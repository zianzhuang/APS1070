{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Tutorial_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTpnyUEJrAjE"
      },
      "source": [
        "# APS1070\n",
        "#### PCA - Tutorial 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS-L6yG_wA4L"
      },
      "source": [
        "### Principle Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O1iW5umwA4N"
      },
      "source": [
        "As you get deeper in the world of data science, you'll learn that in practice it's very uncommon to work with datasets that are 2 or 3 dimensional, and so can be plotted directly. We're now going to look at _dimensionality reduction_ : a category of unsupervised algorithms which attempt to collapse high-dimensional datasets into a low-dimensional space.\n",
        "\n",
        "As suggested above, one reason to do this is to aid visualization. However, that's far from the only reason dimensionality reduction is useful! These techniques also allow us to filter noise, extract useful features, and accomplish much more.\n",
        "\n",
        "Let's dive into PCA with the Iris dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "bD4i39QVwA4O"
      },
      "source": [
        "### PCA - Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "C1__6BbHwA4Q"
      },
      "source": [
        "1. Standardize the data.\n",
        "\n",
        "\n",
        "2. Obtain the Eigenvectors and Eigenvalues from the Covariance matrix (or Correlation matrix), or perform Singular Vector Decomposition.\n",
        "\n",
        "\n",
        "3. Sort eigenvalues in descending order and choose the ùëò eigenvectors that correspond to the ùëò largest eigenvalues where ùëò is the number of dimensions of the new feature subspace. ùëò is less than original dimensionality.\n",
        "\n",
        "\n",
        "4. Construct the projection matrix ùêñ from the selected ùëò eigenvectors.\n",
        "\n",
        "\n",
        "5. Transform the original dataset ùêó via ùêñ to obtain a ùëò-dimensional feature subspace ùêò."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "FNAgpf18wA4S"
      },
      "source": [
        "## PCA - Iris dataset\n",
        "\n",
        "What's that flower?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "T43VN96KwA4T"
      },
      "source": [
        "### Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "lHl0WpQXwA4U"
      },
      "source": [
        "For the following tutorial, we will be working with the famous \"Iris\" dataset that has been deposited on the UCI machine learning repository\n",
        "(https://archive.ics.uci.edu/ml/datasets/Iris).\n",
        "\n",
        "The iris dataset contains measurements for 150 iris flowers from three different species.\n",
        "\n",
        "The three classes in the Iris dataset are:\n",
        "1. Iris-setosa (n=50)\n",
        "1. Iris-versicolor (n=50)\n",
        "1. Iris-virginica (n=50)\n",
        "\n",
        "And the four features of in Iris dataset are:\n",
        "1. sepal length in cm\n",
        "1. sepal width in cm\n",
        "1. petal length in cm\n",
        "1. petal width in cm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "b8sN2l0qwA4W"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zZ5-gEypwA4Y"
      },
      "source": [
        "df = pd.read_csv(filepath_or_buffer='https://raw.githubusercontent.com/aps1070-2019/datasets/master/iris.data', \n",
        "    header=None, \n",
        "    sep=',')\n",
        "\n",
        "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Psv8_JdywA4c"
      },
      "source": [
        "# split data table into data X and class labels y\n",
        "\n",
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,4].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "vaRZjIOxwA4d"
      },
      "source": [
        "labels = set(y)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "L9ZDlBmcwA4f"
      },
      "source": [
        "### Exploratory Data Analysis\n",
        "\n",
        "Let's explore a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "dENHj85lwA4g"
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12,12))\n",
        "noOfCols = X.shape[1]\n",
        "\n",
        "# iterate over each column (feature), and plot in separate sub-plot.\n",
        "for col in range(noOfCols):\n",
        "    # plot data for different labels for choosen column (feature).\n",
        "    for label in labels:\n",
        "        axes.flat[col].hist(X[y==label, col], alpha=0.5, label=label)\n",
        "        \n",
        "    axes.flat[col].legend(loc='upper right')\n",
        "    axes.flat[col].set(xlabel=df.columns[col], ylabel='count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "nXfzK9CcwA4h"
      },
      "source": [
        "As one can see, no feature can on it's own predict the class of the flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "O4j1k5kQwA4i"
      },
      "source": [
        "### Standardizing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "oBY8bzDIwA4i"
      },
      "source": [
        "Since PCA yields a feature subspace that maximizes the variance along the axes, it makes sense to standardize the data, especially, if it was measured on different scales. \n",
        "\n",
        "Although, all features in the Iris dataset were measured in centimeters, let us continue with the transformation of the data onto unit scale (mean=0 and variance=1), which is a requirement for the optimal performance of many machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "yVjRCFeYwA4i"
      },
      "source": [
        "X_std = StandardScaler().fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6FDq2CGrwA4k"
      },
      "source": [
        "X[:, 0].mean(), X_std[:, 0].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "QR_2aGVAwA4l"
      },
      "source": [
        "X[:, 0].var(), X_std[:, 0].var()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ygStRCddwA4m"
      },
      "source": [
        "### Eigendecomposition - Computing Eigenvectors and Eigenvalues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ev9gsv6cwA4n"
      },
      "source": [
        "The eigenvectors and eigenvalues of a covariance (or correlation) matrix represent the \"core\" of a PCA: The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude. In other words, the eigenvalues explain the variance of the data along the new feature axes.\n",
        "\n",
        "The classic approach to PCA is to perform the eigendecomposition on the covariance matrix Œ£, which is a ùëë√óùëë matrix where each element represents the covariance between two features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "Gv0o_pemwA4n"
      },
      "source": [
        "#### Using Covariance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "UTcVKn19wA4n"
      },
      "source": [
        "n, m = X_std.shape\n",
        "\n",
        "# Compute covariance matrix\n",
        "C = np.dot(X_std.T, X_std) / (n-1) \n",
        "# or C = np.cov(X_std.T)\n",
        "\n",
        "# Eigen decomposition\n",
        "eigenValues, eigenVectors = np.linalg.eig(C) \n",
        "print (\"Eig Vec:\\n \",eigenVectors, \" \\n Eig Val: \\n\", eigenValues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKGe0r8CsdUU"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/aps1070-2019/datasets/master/img/eig.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "hB8o63P1wA4r"
      },
      "source": [
        "#### Sort based on eigenValues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "f-B_5GCqwA4r"
      },
      "source": [
        "Decreasing order of eigenValues.\n",
        "It was not needed in this case as eigenValues were already in decreasing order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "GxQuArIxwA4s"
      },
      "source": [
        "args = (-eigenValues).argsort()\n",
        "eigenValues = eigenValues[args]\n",
        "eigenVectors = eigenVectors[:, args]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "W7lnbl5rwA4s"
      },
      "source": [
        "### Explained Variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "uAHXFWEhwA4t"
      },
      "source": [
        "eigValSum = sum(eigenValues)\n",
        "expVar = [eigV/eigValSum*100 for eigV in eigenValues]\n",
        "cumExpVar = np.cumsum(expVar)\n",
        "cumExpVar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "eOWbN9JMwA4u"
      },
      "source": [
        "plt.bar(range(4), expVar, label='Explained Variance')\n",
        "plt.plot(cumExpVar, 'r-o', label='Cumulative Explained Variance')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "piPsUb_WwA4w"
      },
      "source": [
        "How many eigenValues are needed to explain more than 95% of variance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "hKdHSIMRwA4w"
      },
      "source": [
        "### Projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "TwRgX29MwA4w"
      },
      "source": [
        "Since only 2 eigenVectors are enough to explain more than 95% of variance, we'll create the projection matrix using the first 2 eigenVectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL4LkhL-zVlV"
      },
      "source": [
        "PC_count = 2   # Number of PCs\n",
        "x_feature = 0  # Plot x-axis \n",
        "y_feature = 1  # Plot y_axis\n",
        "\n",
        "# Original Data \n",
        "for label in labels:\n",
        "    plt.plot(X_std[y==label, x_feature], X_std[y==label, y_feature], 'o', label=label)\n",
        "    plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "Qk8M2BZ-wA4x"
      },
      "source": [
        "W = eigenVectors[:, 0:PC_count]\n",
        "W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "XJtZ0sm9wA4y"
      },
      "source": [
        "projX = np.dot(X_std, W)\n",
        "X_std.shape, W.shape , projX.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "WBsjMusWwA4z"
      },
      "source": [
        "## Projection\n",
        "for label in labels:\n",
        "    plt.plot(projX[y==label, x_feature], projX[y==label, y_feature], 'o', label=label)\n",
        "    plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYLxLCkAy7Rg"
      },
      "source": [
        "# Reconstruction\n",
        "ReconX = np.dot(projX, W.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZphvlyGyNDN"
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"Original Data\")\n",
        "for label in labels:\n",
        "    plt.plot(X_std[y==label, x_feature], X_std[y==label, y_feature], 'o', label=label)\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Reconstruction Data\")\n",
        "for label in labels:\n",
        "    plt.plot(ReconX[y==label, x_feature], ReconX[y==label, y_feature], 'o', label=label)\n",
        "    plt.legend(loc='upper right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "KLcjU-SpwA40"
      },
      "source": [
        "What has PCA helped us achieve here?\n",
        "\n",
        "1. Visualization: easier visualization of all 3 classes\n",
        "2. Classification: a flower of unknown class can be plotted here, and then classified visually or using algorithms (such as KNNs) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "gJCJALLSwA40"
      },
      "source": [
        "We have used PCA on numerical data. But can it used on Image data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt-Ax98Z49Ou"
      },
      "source": [
        "## Summarizing PCA: \n",
        "\n",
        "Assume we have a dataset with 1000 samples and 5000 features for each sample: **X: (1000, 5000)**. Total elements: **5,000,000**\n",
        "\n",
        "\n",
        "\n",
        "1.   We apply PCA, we get **W: (5000, 5000)**\n",
        "2.   We determine only 10 PCs are enough: **W_op: (5000, 10)**\n",
        "3.   We apply projection: **X @ W_op = Proj (1000, 10)**\n",
        "4.   Now data is summarized in **Proj:(1000,10)** and **W_op: (5000, 10)** Total elements: **60,000**!!!\n",
        "5.   Reconstruction: **Proj @ W_op.T = Recon (1000, 5000)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdrcWQkPwA41"
      },
      "source": [
        "## Eigenfaces\n",
        "\n",
        "Let's face the Eigen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE2BzmQwwA41"
      },
      "source": [
        "**Eigenfaces** is the name given to a set of **eigenvectors** when they are used in the computer vision problem of human face recognition. The approach of using eigenfaces for recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2tIECfhwA41"
      },
      "source": [
        "Eigenfaces refers to an appearance-based approach to face recognition that seeks to capture the variation in a collection of face images and use this information to encode and compare images of individual faces in a holistic (as opposed to a parts-based or feature-based) manner. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_enOO43OwA42"
      },
      "source": [
        "The motivation of Eigenfaces is twofold:\n",
        "\n",
        "1. Extract the relevant facial information, which may or may not be directly related to human intuition of face features such as the eyes, nose, and lips. One way to do so is to capture the statistical variation between face images.\n",
        "2. Represent face images efficiently. To reduce the computation and space complexity, each face image can be represented using a small number of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIhpwQNywA42"
      },
      "source": [
        "Images are downloaded from [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBMcokRhwA42"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGUeUKD3wA43"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import wget\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Gmb-W_wA44"
      },
      "source": [
        "# Download and unzip dataset.\n",
        "filename = wget.download('https://github.com/aps1070-2019/datasets/raw/master/lfw-a.tgz', 'lfw-a.tgz')\n",
        "!tar -xvzf \"{filename}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t5oalpIwA45"
      },
      "source": [
        "# constants\n",
        "IMAGE_DIR = 'lfw'\n",
        "DEFAULT_SIZE = [250, 250] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SulKzP8RwA46"
      },
      "source": [
        "# Reads images from filesystem and returns Array of images and imageNames.\n",
        "def readImages(imagePath = IMAGE_DIR, defaultSize = DEFAULT_SIZE):\n",
        "    images = []\n",
        "    imageNames = []\n",
        "    imageDirs = [image for image in os.listdir(imagePath) if not image.startswith('.')]\n",
        "\n",
        "    for imageDir in imageDirs:\n",
        "        dirPath = os.path.join(imagePath, imageDir)\n",
        "        dirImageNames = [image for image in os.listdir(dirPath) if not image.startswith('.')]\n",
        "        \n",
        "        for imageName in dirImageNames:\n",
        "            image = Image.open(os.path.join(dirPath, imageName))\n",
        "            image = image.convert (\"L\") # L stands for Luminance: converts image to grayscale\n",
        "            \n",
        "            if (defaultSize is not None):\n",
        "                image = image.resize(defaultSize, Image.ANTIALIAS) # resize image\n",
        "                \n",
        "            images.append(np.asarray(image, dtype = np.uint8))\n",
        "            imageNames.append(imageDir)\n",
        "    return [images, imageNames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSMkCl1wA47"
      },
      "source": [
        "[X, y] = readImages()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVYbe2uwwA47"
      },
      "source": [
        "type(X), len(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqsTI0SnwA48"
      },
      "source": [
        "type(X[0]), X[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgMFhq-CwA49"
      },
      "source": [
        "type(y), len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHmuHnQtui4f"
      },
      "source": [
        "print (X[40] ,\"\\n\", y[40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Q9Eoa4_2wA4-"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "vGWt-jZJwA4-"
      },
      "source": [
        "Check from dataset if this image has correct label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6-CEEbJEwA4-"
      },
      "source": [
        "print('Image name is: ', y[40])\n",
        "plt.imshow(X[40], cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJkd9dfuvC4G"
      },
      "source": [
        "print(X[40][100:120,100:110])\n",
        "plt.imshow(X[40][100:120,100:120] ,cmap=plt.cm.gray )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5l9iqcE6wA4_"
      },
      "source": [
        "Creating a mean face from all dataset faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "g0uDu21uwA5A"
      },
      "source": [
        "def asRowMatrix(X):\n",
        "    if len(X) == 0: return np.array([])\n",
        "    rowMatrix = np.empty((0, X[0].size), dtype = X[0].dtype)\n",
        "    for img in X:\n",
        "        rowMatrix = np.vstack((rowMatrix, np.asarray(img).reshape(1, -1)))\n",
        "    return rowMatrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zC7vuHXrwA5A"
      },
      "source": [
        "XMat = asRowMatrix(X);\n",
        "meanImage = np.reshape(XMat.mean(axis=0), X[0].shape)\n",
        "plt.imshow(meanImage, cmap=plt.cm.gray)\n",
        "plt.title('Mean Face')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ArDUCGwsdm"
      },
      "source": [
        "XMat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN2KkKwuwA5B"
      },
      "source": [
        "### Eigendecomposition - Computing Eigenvectors and Eigenvalues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltocG-EywA5B"
      },
      "source": [
        "#### Using Covariance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPEL3OAOwA5B"
      },
      "source": [
        "def getBasisCountThatPreservesVariance(eigenValues, variance=0.98):\n",
        "    for idx, cumulativeSum in enumerate(np.cumsum(eigenValues) / np.sum(eigenValues)):\n",
        "        if cumulativeSum > variance:\n",
        "            return idx\n",
        "        \n",
        "def pca(X, y):\n",
        "    n, d = X.shape\n",
        "    mu = X.mean(axis=0)\n",
        "    X = X - mu # standardising data\n",
        "    \n",
        "    if n > d:\n",
        "        C = np.dot(X.T,x) # covariance matrix\n",
        "        eigenValues, eigenVectors = np.linalg.eigh(C)\n",
        "    else:\n",
        "        C = np.dot(X,X.T) # covariance matrix\n",
        "        eigenValues, eigenVectors = np.linalg.eigh(C)\n",
        "        eigenVectors = np.dot(X.T, eigenVectors)\n",
        "        for i in range(n):\n",
        "            eigenVectors[:,i] = eigenVectors[:, i] / np.linalg.norm(eigenVectors[:, i])\n",
        "\n",
        "    print (\"Dim of Full Eigen Vectors\", eigenVectors.shape)\n",
        "            \n",
        "    # sort eigenVectors in descending order by their eigenValue\n",
        "    idx = np.argsort(-eigenValues)\n",
        "    eigenValues = eigenValues[idx]\n",
        "    eigenVectors = eigenVectors[:, idx]\n",
        "    \n",
        "    # select based on numOfBasis\n",
        "    numOfBasis = getBasisCountThatPreservesVariance(eigenValues)\n",
        "    print('Number of useful eigenBasis are: ', numOfBasis)\n",
        "    eigenValues = eigenValues[0:numOfBasis].copy()\n",
        "    eigenVectors = eigenVectors[:, 0:numOfBasis].copy()\n",
        "    return eigenValues, eigenVectors, mu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlViUOdGwA5C"
      },
      "source": [
        "Below image explains the PCA code above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3fKy1eZwA5C"
      },
      "source": [
        "<img src='https://github.com/aps1070-2019/datasets/raw/master/img/eig-decom.png' />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "J53DJLjowA5C"
      },
      "source": [
        "eigenValues, eigenVectors, mean = pca(XMat, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg9R-uNfyYcc"
      },
      "source": [
        "eigenValues.shape , eigenVectors.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMYy6PoswA5D"
      },
      "source": [
        "# Above code in pca method is written because below code is computationally time taking.\n",
        "# C = np.dot(XMat.T, XMat) # covariance matrix\n",
        "# eigenValues, eigenVectors = np.linalg.eigh(C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "cwM5cWedwA5D"
      },
      "source": [
        "#### EigenFaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "YFYzpq09wA5E"
      },
      "source": [
        "**What were dimensions of eigenVector in the case of Iris example?**\n",
        "\n",
        "Array of size = number of features (4 in the case of Iris).\n",
        "Array of size 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "nxEafj3KwA5E"
      },
      "source": [
        "**What will be dimensions of eigenVector in this example?**\n",
        "\n",
        "Array of size = feature size (62500). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "t-qL2GNIwA5E"
      },
      "source": [
        "eigenVectors[:, 0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "GxSK27XVwA5F"
      },
      "source": [
        "If the dimensions of eigenVector is same as the vectorised image.\n",
        "\n",
        "What if eigenVector is displayed in image format.\n",
        "\n",
        "This is called **eigenFace.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "t3GrCYkEwA5F"
      },
      "source": [
        "# show the first eigenFace\n",
        "plt.imshow(eigenVectors[:, 0].reshape(-1, 250), cmap = plt.cm.gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "6jJn4-2UwA5G"
      },
      "source": [
        "# print first 6 eigen faces\n",
        "COUNT = 6\n",
        "ROWS = math.ceil(COUNT/3)\n",
        "fig = plt.figure(figsize=(12, ROWS * 4))\n",
        "for i in range(0, COUNT):\n",
        "    plt.subplot(ROWS, 3, i+1)\n",
        "    plt.imshow(eigenVectors[:, i].reshape(-1, 250), cmap = plt.cm.gray)\n",
        "    plt.title('#{}'.format(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ccRlRbqzwA5H"
      },
      "source": [
        "By only using first few eigenFaces:\n",
        "1. How would you get a face with white hair.\n",
        "2. Answer the same for black hair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "k7Pf-PxKwA5H"
      },
      "source": [
        "Have a good look at eigenFace number 5.\n",
        "\n",
        "Good luck sleeping tonight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Zokx6LFTwA5H"
      },
      "source": [
        "1. **Plot the next 6 eigenFaces.**\n",
        "2. **Do you observe any difference observed between the first 6 and second 6.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "qg2O0RCBwA5H"
      },
      "source": [
        "### Projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "J3NaLugLwA5H"
      },
      "source": [
        "Now, we will reconstruct an image from the dataset using eigenFaces (eigenVectors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "FVACeDpdwA5H"
      },
      "source": [
        "IMAGE_IDX = 10 # image idx in dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "e2y0pup7wA5L"
      },
      "source": [
        "# actual image\n",
        "plt.imshow(X[IMAGE_IDX], cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "_F7DWoONwA5I"
      },
      "source": [
        "def project (W , X , mu):\n",
        "    return np.dot (X - mu , W)\n",
        "def reconstruct (W , Y , mu) :\n",
        "    return np.dot (Y , W.T) + mu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "yOEjhbP4wA5J"
      },
      "source": [
        "# create reconstructed images\n",
        "COUNT = 6 # count of first eigenVectors used to reconstruct the image\n",
        "reconImages = []\n",
        "for numEvs in range (1, COUNT+1):\n",
        "    P = project(eigenVectors[:, 0:numEvs], X[IMAGE_IDX].reshape(1, -1), mean)\n",
        "    R = reconstruct(eigenVectors[:, 0:numEvs], P, mean)\n",
        "    reconImages.append(R.reshape(X[0].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "owMA50x1wA5J"
      },
      "source": [
        "# plot reconstructed images\n",
        "ROWS = math.ceil(COUNT/3)\n",
        "fig = plt.figure(figsize=(12, ROWS * 4))\n",
        "for i in range(0, COUNT):\n",
        "    plt.subplot(ROWS, 3, i+1)\n",
        "    plt.imshow(reconImages[i], cmap = plt.cm.gray)\n",
        "    plt.title('#{}'.format(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "DjS3_lALwA5K"
      },
      "source": [
        "# create reconstructed images\n",
        "numEvsSet = [1, 10 , 100, 200, 400, 500, 535] # these no. of eigenVectors will be used to reconstruct the image.\n",
        "COUNT = len(numEvsSet)\n",
        "reconImages = []\n",
        "for numEvs in numEvsSet:\n",
        "    P = project(eigenVectors[:, 0:numEvs], X[IMAGE_IDX].reshape(1, -1), mean)\n",
        "    R = reconstruct(eigenVectors[:, 0:numEvs], P, mean)\n",
        "    reconImages.append(R.reshape(X[0].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "egSPF9jrwA5K"
      },
      "source": [
        "# plot reconstructed images\n",
        "ROWS = math.ceil(COUNT/3)\n",
        "fig = plt.figure(figsize=(12, ROWS * 4))\n",
        "for i in range(0, COUNT):\n",
        "    plt.subplot(ROWS, 3, i+1)\n",
        "    plt.imshow(reconImages[i], cmap = plt.cm.gray)\n",
        "    plt.title(\"Reconstruction:\"+ str(numEvsSet[i]) + \" Components\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh4Yfmtr8DJr"
      },
      "source": [
        "####Let's create an animation of reconstruction!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSsTU6tA5tIS"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ims = []\n",
        "reconImages = []\n",
        "\n",
        "for numEvs in range (0 , eigenVectors.shape[1]):\n",
        "    if numEvs % 50 ==0:\n",
        "      print (\"Progress: %.2f \" % (numEvs *100/ eigenVectors.shape[1]), \"%\")\n",
        "\n",
        "    title = plt.text(125.5,0.85, \"\", bbox={'facecolor':'w', 'alpha':1, 'pad':5},\n",
        "                 ha=\"center\")\n",
        "\n",
        "    P = project(eigenVectors[:, 0:numEvs], X[IMAGE_IDX].reshape(1, -1), mean)\n",
        "    R = reconstruct(eigenVectors[:, 0:numEvs], P, mean)\n",
        "    reconImages=(R.reshape(X[0].shape))\n",
        "    title.set_text(\"Reconstruction:\"+ str(numEvs) + \" Components\")\n",
        "    im = plt.imshow(reconImages, cmap = plt.cm.gray)\n",
        "    ims.append([im, title])\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
        "                                repeat_delay=1000)\n",
        "\n",
        "ani.save('dynamic_images.mp4')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('dynamic_images.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}